{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332646a2",
   "metadata": {},
   "source": [
    "# DDA4210 Tutorial 7: Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876b552",
   "metadata": {},
   "source": [
    "1. TA: Dong QIAO\n",
    "2. Email: dongqiao@link.cuhk.edu.cn\n",
    "3. Office: Big Room 74, SDS Research Space on 4th Floor of Zhixin Bldg\n",
    "4. Version: Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88331a67",
   "metadata": {},
   "source": [
    "# Introduction to Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fbf7d",
   "metadata": {},
   "source": [
    "1. AutoEncoder (AE) is a type of neural network designed to learn an approximate identity transformation using an unsupervised way and then to reconstruct high-dimensional data and consists of an encoder network $f_\\phi$ and a decoder network $g_\\theta$, parameterized by $\\phi$, $\\theta$ respectively.\n",
    "\n",
    "2. The middle layer of AE usually has a narrow bottleneck to compress original high-dimensional data to low-dimensional representations.\n",
    "\n",
    "3. VAE aims to transform $\\mathbf{x}$ into a prior distribution $p_z$ (rather than a fixed vector $\\mathbf{z}$) using encoder $f_\\phi$ and then to reconstruct $\\mathbf{x}$ using decoder $g_\\theta$.\n",
    "\n",
    "4. Given training data $\\mathbf{X} = \\{\\mathbf{x}_1, \\mathbf{x}_2, \\dots , \\mathbf{x}_n\\}$ and a prior distribution $p_z$. Assume we have trained $f_\\phi$ and $g_\\theta$ of VAE successfully. In order to generate a new sample that looks like a real data point $\\mathbf{x}_i$, we need the following steps:\n",
    "    * First, sample a $\\mathbf{z}_i$ from the prior distribution $p_z$.\n",
    "    * Then, a new sample can be generated via the decoder, i.e., $g_\\theta(\\mathbf{z}_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad1833",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5efcc7",
   "metadata": {},
   "source": [
    "1. Basic Implementation\n",
    "    * Import packages\n",
    "    * Download dataset\n",
    "    * Define our model\n",
    "    * Define the loss function\n",
    "    * Training\n",
    "2. Assessing a Variational Autoencoder on MNIST using Pytorch\n",
    "    * Test: Comparing Original Images with their Reconstructions\n",
    "    * Data Generation\n",
    "    * Visualize the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40246345",
   "metadata": {},
   "source": [
    "# Basic Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b4400",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4379a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torchvision                             # contains image datasets and many functions to manipulate images\n",
    "import torchvision.transforms as transforms    # to normalize, scale etc the dataset\n",
    "from torch.utils.data import DataLoader        # to load data into batches (for SGD)\n",
    "from torchvision.utils import make_grid        # Plotting. Makes a grid of tensors\n",
    "from torchvision.datasets import MNIST         # the classic handwritten digits dataset\n",
    "import matplotlib.pyplot as plt                # to plot our images\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a85d8",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object.s Notice that ToTensor() transforms images to pytorch\n",
    "# tensors AND scales the pixel values to be within [0, 1]. Also, we have separate Dataset\n",
    "# objects for training and test sets. Data will be downloaded to a folder called 'data'.\n",
    "trainset = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset  = MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Create DataLoader objects. These will give us our batches of training and testing data.\n",
    "batch_size = 100\n",
    "\n",
    "#########################\n",
    "# load dataset\n",
    "#########################\n",
    "pass\n",
    "#########################\n",
    "# End\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe18d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn                          # Class that implements a model (such as a Neural Network)\n",
    "import torch.nn.functional as F                # contains activation functions, sampling layers etc\n",
    "import torch.optim as optim                    # For optimization routines such as SGD, ADAM, ADAGRAD, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02182ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_hidden = 500        # Number of hidden units in the encoder. See AEVB paper page 7, section \"Marginal Likelihood\"\n",
    "d_hidden = 500        # Number of hidden units in the decoder. See AEVB paper page 7, section \"Marginal Likelihood\"\n",
    "latent_dim = 2        # Dimension of latent space. See AEVB paper, page 7, section \"Marginal Likelihood\"\n",
    "learning_rate = 0.001 # For optimizer (SGD or Adam)\n",
    "weight_decay = 1e-5   # For optimizer (SGD or Adam)\n",
    "epochs = 10           # Number of sweeps through the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c05e89",
   "metadata": {},
   "source": [
    "## Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Variational Auto-Encoder Class\"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoding Layers\n",
    "        self.e_input2hidden = nn.Linear(in_features=784, out_features=e_hidden)\n",
    "        self.e_hidden2mean = nn.Linear(in_features=e_hidden, out_features=latent_dim)\n",
    "        self.e_hidden2logvar = nn.Linear(in_features=e_hidden, out_features=latent_dim)\n",
    "        \n",
    "        # Decoding Layers\n",
    "        self.d_latent2hidden = nn.Linear(in_features=latent_dim, out_features=d_hidden)\n",
    "        self.d_hidden2image = nn.Linear(in_features=d_hidden, out_features=784)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        #####################\n",
    "        # Define encoder\n",
    "        #####################\n",
    "        \n",
    "        # Shape Flatten image to [batch_size, input_features]\n",
    "        x = x.view(-1, 784)\n",
    "        # Feed x into Encoder to obtain mean and logvar\n",
    "        pass\n",
    "        \n",
    "        #####################\n",
    "        # End\n",
    "        #####################\n",
    "        return self.e_hidden2mean(x), self.e_hidden2logvar(x)\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        #####################\n",
    "        # Define encoder\n",
    "        #####################\n",
    "        pass\n",
    "        #####################\n",
    "        # Define encoder\n",
    "        #####################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder image to latent representation mean & std\n",
    "        mu, logvar = self.encoder(x)\n",
    "        \n",
    "        # Sample z from latent space using mu and logvar\n",
    "        if self.training:\n",
    "            z = torch.randn_like(mu).mul(torch.exp(0.5*logvar)).add_(mu)\n",
    "        else:\n",
    "            z = mu\n",
    "        \n",
    "        # Feed z into Decoder to obtain reconstructed image. Use Sigmoid as output activation (=probabilities)\n",
    "        x_recon = self.decoder(z)\n",
    "        \n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b991254",
   "metadata": {},
   "source": [
    "## Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7705c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "def vae_loss(image, reconstruction, mu, logvar):\n",
    "    \"\"\"Loss for the Variational AutoEncoder.\"\"\"\n",
    "    # Binary Cross Entropy for batch\n",
    "    BCE = F.binary_cross_entropy(input=reconstruction.view(-1, 28*28), target=image.view(-1, 28*28), reduction='sum')\n",
    "    \n",
    "    ###############################\n",
    "    # Closed-form KL Divergence\n",
    "    ###############################\n",
    "    pass\n",
    "    ###############################\n",
    "    # End\n",
    "    ###############################\n",
    "    \n",
    "    return BCE - KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d843ac",
   "metadata": {},
   "source": [
    "## Instantiate VAE and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate VAE with Adam optimizer\n",
    "vae = VAE()\n",
    "vae = vae.to(device)    # send weights to GPU. Do this BEFORE defining Optimizer\n",
    "optimizer = optim.Adam(params=vae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "vae.train()            # tell the network to be in training mode. Useful to activate Dropout layers & other stuff\n",
    "\n",
    "# Train\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Store training losses & instantiate batch counter\n",
    "    losses.append(0)\n",
    "    number_of_batches = 0\n",
    "\n",
    "    ##################################\n",
    "    # Train the model for each batch\n",
    "    ##################################\n",
    "    \n",
    "    # Grab the batch, we are only interested in images not on their labels\n",
    "    for images, _ in trainloader:\n",
    "        # Save batch to GPU, remove existing gradients from previous iterations\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed images to VAE. Compute Loss.\n",
    "        pass\n",
    "\n",
    "        # Backpropagate the loss & perform optimization step with such gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add loss to the cumulative sum\n",
    "        losses[-1] += loss.item()  \n",
    "        number_of_batches += 1\n",
    "        \n",
    "    ##################################\n",
    "    # Train the model for each batch\n",
    "    ##################################\n",
    "\n",
    "    # Update average loss & Log information\n",
    "    losses[-1] /= number_of_batches\n",
    "    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, epochs, losses[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07702f00",
   "metadata": {},
   "source": [
    "# Assessing a Variational Autoencoder on MNIST using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ea714",
   "metadata": {},
   "source": [
    "## Comparing Original Images with their Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original images\n",
    "test_images = images\n",
    "    \n",
    "with torch.no_grad():\n",
    "    print(\"Original Images\")\n",
    "    test_images = test_images.cpu()\n",
    "    test_images = test_images.clamp(0, 1)\n",
    "    test_images = test_images[:50]\n",
    "    test_images = make_grid(test_images, 10, 5)\n",
    "    test_images = test_images.numpy()\n",
    "    test_images = np.transpose(test_images, (1, 2, 0))\n",
    "    plt.imshow(test_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d129f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display reconstructed images\n",
    "with torch.no_grad():\n",
    "    print(\"Reconstructions\")\n",
    "    reconstructions = reconstructions.view(reconstructions.size(0), 1, 28, 28)\n",
    "    reconstructions = reconstructions.cpu()\n",
    "    reconstructions = reconstructions.clamp(0, 1)\n",
    "    reconstructions = reconstructions[:50]\n",
    "    plt.imshow(np.transpose(make_grid(reconstructions, 10, 5).numpy(), (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set VAE to evaluation mode (deactivates potential dropout layers)\n",
    "# So that we use the latent mean and we don't sample from the latent space\n",
    "vae.eval()\n",
    "\n",
    "# Keep track of test loss (notice, we have no epochs)\n",
    "test_loss, number_of_batches = 0.0, 0\n",
    "\n",
    "for test_images, _ in testloader:\n",
    "\n",
    "  # Do not track gradients\n",
    "  with torch.no_grad():\n",
    "\n",
    "    # Send images to the GPU/CPU\n",
    "    test_images = test_images.to(device)\n",
    "\n",
    "    ##############################################################################\n",
    "    # Feed images through the VAE to obtain their reconstruction & compute loss\n",
    "    ##############################################################################\n",
    "    pass\n",
    "    ##############################################################################\n",
    "    # End\n",
    "    ##############################################################################\n",
    "\n",
    "    # Cumulative loss & Number of batches\n",
    "    test_loss += loss.item()\n",
    "    number_of_batches += 1\n",
    "\n",
    "# Now divide by number of batches to get average loss per batch\n",
    "test_loss /= number_of_batches\n",
    "print('average reconstruction error: %f' % (test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d5252",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f19b8",
   "metadata": {},
   "source": [
    "To sample images from the generative model, we can do something like this.\n",
    "\n",
    "1. sample an array with shape [50, latent_dim] of standard normal variates, making sure that this tensor is saved to GPU. \n",
    "2. feed it through the decoder, obtaining a reconstruction, \n",
    "3. reshape it the correct image shape. \n",
    "4. use the usual trick to print images from Pytorch GPU with matplotlib.\n",
    "\n",
    "Notice how we set the VAE in evaluation mode and we make sure that Pytorch doesn’t keep track of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample from standard normal distribution\n",
    "    z = torch.randn(50, latent_dim, device=device)\n",
    "    \n",
    "    # Reconstruct images from sampled latent vectors\n",
    "    recon_images = vae.decoder(z)\n",
    "    recon_images = recon_images.view(recon_images.size(0), 1, 28, 28)\n",
    "    recon_images = recon_images.cpu()\n",
    "    recon_images = recon_images.clamp(0, 1)\n",
    "    \n",
    "    # Plot Generated Images\n",
    "    plt.imshow(np.transpose(make_grid(recon_images, 10, 5).numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4aea7",
   "metadata": {},
   "source": [
    "## Visualize the latent space (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8459ded",
   "metadata": {},
   "source": [
    "Finally, we can also visualize the latent space. Basically we are generating a grid of values in the latent space. Then we are decoding the grid into images, reshaping it and plotting it. The result, looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Create empty (x, y) grid\n",
    "    latent_x = np.linspace(-1.5, 1.5, 20)\n",
    "    latent_y = np.linspace(-1.5, 1.5, 20)\n",
    "    latents = torch.FloatTensor(len(latent_x), len(latent_y), 2)\n",
    "    # Fill up the grid\n",
    "    for i, lx in enumerate(latent_x):\n",
    "    for j, ly in enumerate(latent_y):\n",
    "        latents[j, i, 0] = lx\n",
    "        latents[j, i, 1] = ly\n",
    "    # Flatten the grid\n",
    "    latents = latents.view(-1, 2)\n",
    "    # Send to GPU\n",
    "    latents = latents.to(device)\n",
    "    # Find their representation\n",
    "    reconstructions = vae.decoder(latents).view(-1, 1, 28, 28)\n",
    "    reconstructions = reconstructions.cpu()\n",
    "    # Finally, plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    plt.imshow(np.transpose(make_grid(reconstructions.data[:400], 20, 5).clamp(0, 1).numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b484afe",
   "metadata": {},
   "source": [
    "Notice that since we are using simple linear layers and very few epochs, this will look very messy. For better performance we would need to use convolutional layers in the encoder & decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a025efc",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301fb4d",
   "metadata": {},
   "source": [
    "* Mauro Camara Escudero, 2020, Minimalist Variational Autoencoder in Pytorch with CUDA GPU, https://maurocamaraescudero.netlify.app/post/minimalist-variational-autoencoder-in-pytorch-with-cuda-gpu/\n",
    "\n",
    "* Mauro Camara Escudero, 2020, Assessing a Variational Autoencoder on MNIST using Pytorch, https://maurocamaraescudero.netlify.app/post/assessing-a-variational-autoencoder-on-mnist-using-pytorch/\n",
    "\n",
    "* Durk Kingma. 2020. “Variational Autoencoder in Pytorch.” https://github.com/dpkingma/examples/blob/master/vae/main.py\n",
    "\n",
    "* Federico Bergamin. 2020. “Variational-Autoencoders.” https://github.com/federicobergamin/Variational-Autoencoders/blob/master/VAE.py\n",
    "\n",
    "* Paul Guerrero, Nils Thuerey. 2020. “Smart Geometry Ucl - Variational Autoencoder Pytorch.” https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb#scrollTo=TglLFCT1N7iF\n",
    "\n",
    "* Mauro Camara Escudero, 2020, Variational Auto-Encoders and the Expectation-Maximization Algorithm, https://maurocamaraescudero.netlify.app/post/variational-auto-encoders-and-the-expectation-maximization-algorithm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf76d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myml",
   "language": "python",
   "name": "myml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
